{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category_encoders\n",
      "  Downloading category_encoders-2.2.2-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[K     |████████████████████████████████| 80 kB 27.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.14.0\n",
      "  Downloading numpy-1.21.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.8 MB 96.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=1.0.0\n",
      "  Downloading scipy-1.7.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (28.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 28.4 MB 91.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.20.0\n",
      "  Downloading scikit_learn-1.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.8 MB 88.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting statsmodels>=0.9.0\n",
      "  Downloading statsmodels-0.12.2-cp38-cp38-manylinux1_x86_64.whl (9.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.4 MB 76.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting patsy>=0.5.1\n",
      "  Downloading patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 65.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas>=0.21.1\n",
      "  Downloading pandas-1.3.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 122.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /opt/app-root/lib/python3.8/site-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/app-root/lib/python3.8/site-packages (from pandas>=0.21.1->category_encoders) (2021.1)\n",
      "Requirement already satisfied: six in /opt/app-root/lib/python3.8/site-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 110.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: numpy, threadpoolctl, scipy, patsy, pandas, joblib, statsmodels, scikit-learn, category-encoders\n",
      "Successfully installed category-encoders-2.2.2 joblib-1.0.1 numpy-1.21.2 pandas-1.3.3 patsy-0.5.2 scikit-learn-1.0 scipy-1.7.1 statsmodels-0.12.2 threadpoolctl-2.2.0\n",
      "Requirement already satisfied: minio in /opt/app-root/lib/python3.8/site-packages (6.0.2)\n",
      "Requirement already satisfied: configparser in /opt/app-root/lib/python3.8/site-packages (from minio) (5.0.2)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib/python3.8/site-packages (from minio) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in /opt/app-root/lib/python3.8/site-packages (from minio) (2.8.1)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib/python3.8/site-packages (from minio) (2021.1)\n",
      "Requirement already satisfied: urllib3 in /opt/app-root/lib/python3.8/site-packages (from minio) (1.26.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.8/site-packages (from python-dateutil->minio) (1.15.0)\n",
      "Collecting git+https://github.com/amirgholipour/alibi-detect.git\n",
      "  Cloning https://github.com/amirgholipour/alibi-detect.git to /tmp/pip-req-build-rnyxlvka\n",
      "  Running command git clone -q https://github.com/amirgholipour/alibi-detect.git /tmp/pip-req-build-rnyxlvka\n",
      "  Resolved https://github.com/amirgholipour/alibi-detect.git to commit ae248be3068dc17a46f3ad4359f8b0a12a908007\n",
      "Collecting matplotlib<4.0.0,>=3.0.0\n",
      "  Downloading matplotlib-3.4.3-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 24.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.16.2 in /opt/app-root/lib/python3.8/site-packages (from alibi-detect==0.7.3.dev0) (1.21.2)\n",
      "Requirement already satisfied: pandas<2.0.0,>=0.23.3 in /opt/app-root/lib/python3.8/site-packages (from alibi-detect==0.7.3.dev0) (1.3.3)\n",
      "Collecting Pillow<9.0.0,>=5.4.1\n",
      "  Downloading Pillow-8.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 111.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencv-python<5.0.0,>=3.2.0\n",
      "  Downloading opencv_python-4.5.3.56-cp38-cp38-manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 49.9 MB 108.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy<2.0.0,>=1.3.0 in /opt/app-root/lib/python3.8/site-packages (from alibi-detect==0.7.3.dev0) (1.7.1)\n",
      "Collecting scikit-image!=0.17.1,<0.19,>=0.14.2\n",
      "  Downloading scikit_image-0.18.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (30.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 30.2 MB 115.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn<0.25.0,>=0.20.2\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 102.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow<2.7.0,>=2.0.0\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
      "\u001b[K     |█████████████▍                  | 191.6 MB 176.2 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |█████████████████████████████▎  | 420.1 MB 160.3 MB/s eta 0:00:01"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_probability<0.13.0,>=0.8.0\n",
      "  Downloading tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.8 MB 111.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.0.0\n",
      "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 86.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dill<0.4.0,>=0.3.0\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[K     |████████████████████████████████| 86 kB 110.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.28.1 in /opt/app-root/lib/python3.8/site-packages (from alibi-detect==0.7.3.dev0) (4.60.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/app-root/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect==0.7.3.dev0) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib/python3.8/site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect==0.7.3.dev0) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 105.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /opt/app-root/lib/python3.8/site-packages (from cycler>=0.10->matplotlib<4.0.0,>=3.0.0->alibi-detect==0.7.3.dev0) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/app-root/lib/python3.8/site-packages (from pandas<2.0.0,>=0.23.3->alibi-detect==0.7.3.dev0) (2021.1)\n",
      "Collecting networkx>=2.0\n",
      "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 105.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.1.1-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 101.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting imageio>=2.3.0\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 108.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tifffile>=2019.7.26\n",
      "  Downloading tifffile-2021.8.30-py3-none-any.whl (171 kB)\n",
      "\u001b[K     |████████████████████████████████| 171 kB 85.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/app-root/lib/python3.8/site-packages (from scikit-learn<0.25.0,>=0.20.2->alibi-detect==0.7.3.dev0) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/app-root/lib/python3.8/site-packages (from scikit-learn<0.25.0,>=0.20.2->alibi-detect==0.7.3.dev0) (1.0.1)\n",
      "Collecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.41.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.9 MB 106.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 106.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.14.0-py3-none-any.whl (131 kB)\n",
      "\u001b[K     |████████████████████████████████| 131 kB 137.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /opt/app-root/lib/python3.8/site-packages (from tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (1.12.1)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 97.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard~=2.6\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 119.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /opt/app-root/lib/python3.8/site-packages (from tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (1.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /opt/app-root/lib/python3.8/site-packages (from tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (0.36.2)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 107.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /opt/app-root/lib/python3.8/site-packages (from tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (3.15.8)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 124.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting numpy<2.0.0,>=1.16.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9 MB 111.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 138.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 64.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 101.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=0.11.15\n",
      "  Downloading Werkzeug-2.0.1-py3-none-any.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 130.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 111.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/app-root/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/app-root/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (57.4.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 110.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /opt/app-root/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (1.30.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/app-root/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/app-root/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/app-root/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/app-root/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/app-root/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/app-root/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/app-root/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/app-root/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/app-root/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.7.0,>=2.0.0->alibi-detect==0.7.3.dev0) (3.1.0)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in /opt/app-root/lib/python3.8/site-packages (from tensorflow_probability<0.13.0,>=0.8.0->alibi-detect==0.7.3.dev0) (1.6.0)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib/python3.8/site-packages (from tensorflow_probability<0.13.0,>=0.8.0->alibi-detect==0.7.3.dev0) (5.0.7)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.6-cp38-cp38-manylinux_2_24_x86_64.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 98.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.8/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect==0.7.3.dev0) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.8/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect==0.7.3.dev0) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.8/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect==0.7.3.dev0) (3.0.12)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 91.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub>=0.0.17\n",
      "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
      "\u001b[K     |████████████████████████████████| 52 kB 73.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib/python3.8/site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect==0.7.3.dev0) (2021.4.4)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 116.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/app-root/lib/python3.8/site-packages (from sacremoses->transformers<5.0.0,>=4.0.0->alibi-detect==0.7.3.dev0) (7.1.2)\n",
      "Building wheels for collected packages: alibi-detect, clang\n",
      "  Building wheel for alibi-detect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alibi-detect: filename=alibi_detect-0.7.3.dev0-py3-none-any.whl size=208636 sha256=0bfbd838e78345794515b03a1839f5d6f36dd14c0cb3fd7db72e564ea0391f1f\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zf1cz0vg/wheels/6f/9a/84/2c029e459d3667898c067649fbbdf41440c99a4c9a44a76b2c\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30693 sha256=c70f267644fa32c28c23c8baacb896941fafe1335e3499b571f0504411c045f5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zf1cz0vg/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built alibi-detect clang\n",
      "Installing collected packages: werkzeug, typing-extensions, tensorboard-plugin-wit, tensorboard-data-server, Pillow, numpy, markdown, kiwisolver, grpcio, google-auth-oauthlib, cycler, absl-py, tokenizers, tifffile, tensorflow-estimator, tensorboard, sacremoses, PyWavelets, opt-einsum, networkx, matplotlib, keras-preprocessing, keras, imageio, huggingface-hub, h5py, google-pasta, gast, flatbuffers, dm-tree, clang, astunparse, transformers, tensorflow-probability, tensorflow, scikit-learn, scikit-image, opencv-python, dill, alibi-detect\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.2\n",
      "    Uninstalling numpy-1.21.2:\n",
      "      Successfully uninstalled numpy-1.21.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0\n",
      "    Uninstalling scikit-learn-1.0:\n",
      "      Successfully uninstalled scikit-learn-1.0\n",
      "Successfully installed Pillow-8.3.2 PyWavelets-1.1.1 absl-py-0.14.0 alibi-detect-0.7.3.dev0 astunparse-1.6.3 clang-5.0 cycler-0.10.0 dill-0.3.4 dm-tree-0.1.6 flatbuffers-1.12 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.41.0 h5py-3.1.0 huggingface-hub-0.0.17 imageio-2.9.0 keras-2.6.0 keras-preprocessing-1.1.2 kiwisolver-1.3.2 markdown-3.3.4 matplotlib-3.4.3 networkx-2.6.3 numpy-1.19.5 opencv-python-4.5.3.56 opt-einsum-3.3.0 sacremoses-0.0.46 scikit-image-0.18.3 scikit-learn-0.24.2 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 tensorflow-probability-0.12.2 tifffile-2021.8.30 tokenizers-0.10.3 transformers-4.11.0 typing-extensions-3.7.4.3 werkzeug-2.0.1\n",
      "Requirement already satisfied: ipynbname in /opt/app-root/lib/python3.8/site-packages (2021.3.2)\n",
      "Requirement already satisfied: ipykernel in /opt/app-root/lib/python3.8/site-packages (from ipynbname) (5.5.3)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /opt/app-root/lib/python3.8/site-packages (from ipykernel->ipynbname) (5.0.5)\n",
      "Requirement already satisfied: jupyter-client in /opt/app-root/lib/python3.8/site-packages (from ipykernel->ipynbname) (6.1.12)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/app-root/lib/python3.8/site-packages (from ipykernel->ipynbname) (6.1)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /opt/app-root/lib/python3.8/site-packages (from ipykernel->ipynbname) (7.22.0)\n",
      "Requirement already satisfied: decorator in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (5.0.7)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (57.4.0)\n",
      "Requirement already satisfied: backcall in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (2.8.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (0.17.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/app-root/lib/python3.8/site-packages (from ipython>=5.0.0->ipykernel->ipynbname) (3.0.18)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/app-root/lib/python3.8/site-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->ipynbname) (0.7.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/app-root/lib/python3.8/site-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->ipynbname) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/app-root/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->ipynbname) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/app-root/lib/python3.8/site-packages (from traitlets>=4.1.0->ipykernel->ipynbname) (0.2.0)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/app-root/lib/python3.8/site-packages (from jupyter-client->ipykernel->ipynbname) (22.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/app-root/lib/python3.8/site-packages (from jupyter-client->ipykernel->ipynbname) (2.8.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/app-root/lib/python3.8/site-packages (from jupyter-client->ipykernel->ipynbname) (4.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel->ipynbname) (1.15.0)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement python-opencv (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for python-opencv\u001b[0m\n",
      "Collecting mlflow\n",
      "  Downloading mlflow-1.20.2-py3-none-any.whl (14.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.6 MB 24.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: entrypoints in /opt/app-root/lib/python3.8/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: requests>=2.17.3 in /opt/app-root/lib/python3.8/site-packages (from mlflow) (2.25.1)\n",
      "Collecting alembic<=1.4.1\n",
      "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 103.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
      "Requirement already satisfied: click>=7.0 in /opt/app-root/lib/python3.8/site-packages (from mlflow) (7.1.2)\n",
      "Requirement already satisfied: sqlalchemy in /opt/app-root/lib/python3.8/site-packages (from mlflow) (1.4.23)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 80.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/app-root/lib/python3.8/site-packages (from mlflow) (20.9)\n",
      "Collecting querystring-parser\n",
      "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting Flask\n",
      "  Downloading Flask-2.0.1-py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 100.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,>=3.7.0 in /opt/app-root/lib/python3.8/site-packages (from mlflow) (4.0.1)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib/python3.8/site-packages (from mlflow) (1.3.3)\n",
      "Requirement already satisfied: pytz in /opt/app-root/lib/python3.8/site-packages (from mlflow) (2021.1)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 59.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib/python3.8/site-packages (from mlflow) (5.4.1)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib/python3.8/site-packages (from mlflow) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle in /opt/app-root/lib/python3.8/site-packages (from mlflow) (1.6.0)\n",
      "Collecting docker>=4.0.0\n",
      "  Downloading docker-5.0.2-py2.py3-none-any.whl (145 kB)\n",
      "\u001b[K     |████████████████████████████████| 145 kB 131.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gitpython>=2.1.0 in /opt/app-root/lib/python3.8/site-packages (from mlflow) (3.1.14)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in /opt/app-root/lib/python3.8/site-packages (from mlflow) (3.15.8)\n",
      "Collecting gunicorn\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "\u001b[K     |████████████████████████████████| 79 kB 115.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Mako in /opt/app-root/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (1.1.5)\n",
      "Collecting python-editor>=0.3\n",
      "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/app-root/lib/python3.8/site-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /opt/app-root/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/app-root/lib/python3.8/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/app-root/lib/python3.8/site-packages (from docker>=4.0.0->mlflow) (0.58.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/app-root/lib/python3.8/site-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/app-root/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/app-root/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/app-root/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/app-root/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/app-root/lib/python3.8/site-packages (from requests>=2.17.3->mlflow) (4.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/app-root/lib/python3.8/site-packages (from sqlalchemy->mlflow) (1.1.1)\n",
      "Collecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 136.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Werkzeug>=2.0 in /opt/app-root/lib/python3.8/site-packages (from Flask->mlflow) (2.0.1)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (30 kB)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/app-root/lib/python3.8/site-packages (from gunicorn->mlflow) (57.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/app-root/lib/python3.8/site-packages (from packaging->mlflow) (2.4.7)\n",
      "Requirement already satisfied: prometheus_client in /opt/app-root/lib/python3.8/site-packages (from prometheus-flask-exporter->mlflow) (0.10.1)\n",
      "Building wheels for collected packages: alembic, databricks-cli, prometheus-flask-exporter\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=1e0611e4a127194738230d0c662f87151f460a1e799116f21a1e63bd91dc9490\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-i7p4hfmj/wheels/9d/de/6d/ca8d461ec29e010b1267d7353d0b058819770f7680bb9360e4\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105259 sha256=9f01405d31a49da82d589c7d2fad8745aabec5ed0ad10e7fabccd316ba7a7310\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-i7p4hfmj/wheels/ee/7e/15/972603d7621ee28090b56554f44bbb1e7ada685b595ef71578\n",
      "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17416 sha256=8d77f4b7e85f82f77e43336fa4de549be6d51016894c699860d6c0ce2212075a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-i7p4hfmj/wheels/69/6f/b4/2087abb1172ae32c58e366dc09746de46a72b0e9fb2c022920\n",
      "Successfully built alembic databricks-cli prometheus-flask-exporter\n",
      "Installing collected packages: MarkupSafe, Jinja2, itsdangerous, python-editor, Flask, sqlparse, querystring-parser, prometheus-flask-exporter, gunicorn, docker, databricks-cli, alembic, mlflow\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.3\n",
      "    Uninstalling Jinja2-2.11.3:\n",
      "      Successfully uninstalled Jinja2-2.11.3\n",
      "  Attempting uninstall: alembic\n",
      "    Found existing installation: alembic 1.7.1\n",
      "    Uninstalling alembic-1.7.1:\n",
      "      Successfully uninstalled alembic-1.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "elyra 2.2.4 requires jinja2<3.0,>=2.11, but you have jinja2 3.0.1 which is incompatible.\u001b[0m\n",
      "Successfully installed Flask-2.0.1 Jinja2-3.0.1 MarkupSafe-2.0.1 alembic-1.4.1 databricks-cli-0.15.0 docker-5.0.2 gunicorn-20.1.0 itsdangerous-2.0.1 mlflow-1.20.2 prometheus-flask-exporter-0.18.2 python-editor-1.0.4 querystring-parser-1.2.4 sqlparse-0.4.2\n"
     ]
    }
   ],
   "source": [
    "# #pip  install alibi-detect --user\n",
    "# # # !pip  install tensorflow\n",
    "# !pip install catboost\n",
    "# !pip install xgboost\n",
    "!pip install category_encoders\n",
    "# # # !pip install torch torchvision torchaudio\n",
    "# !pip install lightgbm\n",
    "# !pip install verta\n",
    "!pip install minio\n",
    "\n",
    "!pip install git+https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi\n",
    "\n",
    "!pip install ipynbname\n",
    "!pip install python-opencv\n",
    "!pip install mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi\n",
      "  Cloning https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi to /tmp/pip-req-build-ooexe456\n",
      "  Running command git clone -q https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi /tmp/pip-req-build-ooexe456\n",
      "  fatal: repository 'https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi/' not found\n",
      "\u001b[33mWARNING: Discarding git+https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi. Command errored out with exit status 128: git clone -q https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi /tmp/pip-req-build-ooexe456 Check the logs for full command output.\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 128: git clone -q https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi /tmp/pip-req-build-ooexe456 Check the logs for full command output.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/amirgholipour/alibi-detect/tree/bugs_free_alibi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libGL.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-eee2e6fdccd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import alibi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malibi_detect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularDrift\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMMDDrift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# from alibi_detect.utils.saving import save_detector, load_detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m  \u001b[0;31m# noqa F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ad\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"models\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"od\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"utils\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/od/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mseq2seq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOutlierSeq2Seq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectralResidual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mllr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLLR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m __all__ = [\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/od/llr.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malibi_detect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseDetector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFitMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mThresholdMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutlier_prediction_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0malibi_detect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0malibi_detect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperturbation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmutate_categorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/utils/perturbation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libGL.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# import alibi\n",
    "\n",
    "from alibi_detect.cd import TabularDrift,MMDDrift\n",
    "# from alibi_detect.utils.saving import save_detector, load_detector\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt    \n",
    "# import seaborn as sns\n",
    "import category_encoders as ce\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from minio import Minio\n",
    "import mlflow\n",
    "import subprocess\n",
    "import ipynbname\n",
    "# from verta import Client\n",
    "# from minio.error import ResponseError\n",
    "\n",
    "# import pickle\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow configuration\n",
    "Configure mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from verta.utils import ModelAPI\n",
    "\n",
    "# # Connect to local MLflow tracking server\n",
    "# mlflow.set_tracking_uri(HOST)\n",
    "\n",
    "# # Set the experiment name...\n",
    "# mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# mlflow.sklearn.autolog(log_input_examples=True)\n",
    "# mlflow.autolog(log_input_examples=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_logged_data(run_id):\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    data = client.get_run(run_id).data\n",
    "    tags = {k: v for k, v in data.tags.items() if not k.startswith(\"mlflow.\")}\n",
    "    artifacts = [f.path for f in client.list_artifacts(run_id, \"model\")]\n",
    "    return data.params, data.metrics, tags, artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO move it to a library\n",
    "import subprocess\n",
    "import ipynbname\n",
    "\n",
    "def get_git_revision_hash():\n",
    "    return subprocess.check_output(['git', 'rev-parse', 'HEAD'])\n",
    "\n",
    "def get_git_revision_short_hash():\n",
    "    return subprocess.check_output(['git', 'rev-parse', '--short', 'HEAD'])\n",
    "\n",
    "def get_git_remote():\n",
    "    return subprocess.check_output(['git', 'config', '--get', 'remote.origin.url'])\n",
    "\n",
    "def get_git_user():\n",
    "    return subprocess.check_output(['git', 'config', 'user.name'])\n",
    "\n",
    "def get_git_branch():\n",
    "    return subprocess.check_output(['git', 'branch', '--show-current'])\n",
    "\n",
    "def get_pip_freeze():\n",
    "    return subprocess.check_output(['pip', 'freeze']).splitlines()\n",
    "\n",
    "\n",
    "def record_details(mlflow):\n",
    "    \"\"\"\n",
    "    This method is the anchor poijt and more activiteis will go in it\n",
    "    :param mlflow:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    with open(\"pip_freeze.txt\", \"wb\") as file:\n",
    "        for line in get_pip_freeze():\n",
    "            file.write(line)\n",
    "            file.write(bytes(\"\\n\", \"UTF-8\"))\n",
    "    mlflow.log_artifact(\"pip_freeze.txt\")\n",
    "    file.close()\n",
    "    os.remove(\"pip_freeze.txt\")\n",
    "\n",
    "\n",
    "def mlflow_grid_search(methodtoexecute, methodarguments):\n",
    "    with mlflow.start_run(tags= {\n",
    "        \"mlflow.source.git.commit\" : get_git_revision_hash() ,\n",
    "        \"mlflow.user\": get_git_user(),\n",
    "        \"mlflow.source.git.repoURL\": get_git_remote(),\n",
    "        \"git_remote\": get_git_remote(),\n",
    "        \"mlflow.source.git.branch\": get_git_branch(),\n",
    "        \"mlflow.docker.image.name\": os.getenv(\"JUPYTER_IMAGE\", \"LOCAL\"),\n",
    "        \"mlflow.source.type\": \"NOTEBOOK\",\n",
    "        \"mlflow.source.name\": ipynbname.name()\n",
    "    }) as run:\n",
    "        methodtoexecute(**methodarguments)\n",
    "        record_details(mlflow)\n",
    "\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_s3_server():\n",
    "    minioClient = Minio('minio-ml-workshop:9000',\n",
    "                    access_key='minio',\n",
    "                    secret_key='minio123',\n",
    "                    secure=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>148</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>45.65</td>\n",
       "      <td>45.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>463</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>101.15</td>\n",
       "      <td>385.90</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>471</td>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>...</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.65</td>\n",
       "      <td>330.60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>496</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>43.75</td>\n",
       "      <td>903.60</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>833</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>70</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>74.10</td>\n",
       "      <td>5222.30</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0         148    Male              0      No         No       1          Yes   \n",
       "1         463    Male              0     Yes        Yes       4          Yes   \n",
       "2         471  Female              1      No         No      17          Yes   \n",
       "3         496    Male              0      No         No      22           No   \n",
       "4         833  Female              0     Yes        Yes      70          Yes   \n",
       "\n",
       "      MultipleLines InternetService       OnlineSecurity  ...  \\\n",
       "0                No             DSL                   No  ...   \n",
       "1               Yes     Fiber optic                   No  ...   \n",
       "2                No              No  No internet service  ...   \n",
       "3  No phone service             DSL                   No  ...   \n",
       "4                No             DSL                  Yes  ...   \n",
       "\n",
       "      DeviceProtection          TechSupport          StreamingTV  \\\n",
       "0                   No                   No                   No   \n",
       "1                  Yes                   No                  Yes   \n",
       "2  No internet service  No internet service  No internet service   \n",
       "3                  Yes                   No                   No   \n",
       "4                  Yes                  Yes                   No   \n",
       "\n",
       "       StreamingMovies        Contract PaperlessBilling  \\\n",
       "0                   No  Month-to-month              Yes   \n",
       "1                  Yes  Month-to-month               No   \n",
       "2  No internet service        One year               No   \n",
       "3                  Yes        One year              Yes   \n",
       "4                  Yes        One year               No   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          45.65         45.65    Yes  \n",
       "1           Electronic check         101.15        385.90    Yes  \n",
       "2               Mailed check          20.65        330.60     No  \n",
       "3  Bank transfer (automatic)          43.75        903.60    Yes  \n",
       "4    Credit card (automatic)          74.10       5222.30     No  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../../data/raw/data.csv')\n",
    "data.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleaning\n",
    "\n",
    "Map the churn data to numeric number.\n",
    "\n",
    "Replace missing value.\n",
    "\n",
    "Remove churn and Customer ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>45.65</td>\n",
       "      <td>45.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>No</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>101.15</td>\n",
       "      <td>385.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>20.65</td>\n",
       "      <td>330.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>22</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>43.75</td>\n",
       "      <td>903.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>70</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Credit card (automatic)</td>\n",
       "      <td>74.10</td>\n",
       "      <td>5222.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0    Male              0      No         No       1          Yes   \n",
       "1    Male              0     Yes        Yes       4          Yes   \n",
       "2  Female              1      No         No      17          Yes   \n",
       "3    Male              0      No         No      22           No   \n",
       "4  Female              0     Yes        Yes      70          Yes   \n",
       "\n",
       "      MultipleLines InternetService       OnlineSecurity         OnlineBackup  \\\n",
       "0                No             DSL                   No                   No   \n",
       "1               Yes     Fiber optic                   No                   No   \n",
       "2                No              No  No internet service  No internet service   \n",
       "3  No phone service             DSL                   No                  Yes   \n",
       "4                No             DSL                  Yes                  Yes   \n",
       "\n",
       "      DeviceProtection          TechSupport          StreamingTV  \\\n",
       "0                   No                   No                   No   \n",
       "1                  Yes                   No                  Yes   \n",
       "2  No internet service  No internet service  No internet service   \n",
       "3                  Yes                   No                   No   \n",
       "4                  Yes                  Yes                   No   \n",
       "\n",
       "       StreamingMovies        Contract PaperlessBilling  \\\n",
       "0                   No  Month-to-month              Yes   \n",
       "1                  Yes  Month-to-month               No   \n",
       "2  No internet service        One year               No   \n",
       "3                  Yes        One year              Yes   \n",
       "4                  Yes        One year               No   \n",
       "\n",
       "               PaymentMethod  MonthlyCharges  TotalCharges  \n",
       "0           Electronic check           45.65         45.65  \n",
       "1           Electronic check          101.15        385.90  \n",
       "2               Mailed check           20.65        330.60  \n",
       "3  Bank transfer (automatic)           43.75        903.60  \n",
       "4    Credit card (automatic)           74.10       5222.30  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "data.replace(\" \", np.nan, inplace=True)\n",
    "\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'])\n",
    "\n",
    "mean = data['TotalCharges'].mean()\n",
    "data.fillna(mean, inplace=True)\n",
    "final_set = data.drop(['Churn', 'customerID'], axis=1)\n",
    "final_set.head(5)\n",
    "labels = data['Churn']\n",
    "\n",
    "\n",
    "final_set.head(5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape (4930, 19) (4930,)\n",
      "Testing Data Shape (2113, 19) (2113,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CustomerChurnDriftFeaturesColumns.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "labels = data['Churn']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(final_set, labels, test_size=0.3)\n",
    "print ('Training Data Shape',X_train.shape, Y_train.shape)\n",
    "print ('Testing Data Shape',X_test.shape, Y_test.shape)\n",
    "\n",
    "Y = data['Churn']\n",
    "X = final_set\n",
    "joblib.dump(final_set.columns, 'CustomerChurnDriftFeaturesColumns.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Define a Drift Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MonthlyCharges', 'TotalCharges', 'tenure', 'SeniorCitizen'] ['Partner', 'Dependents', 'InternetService', 'StreamingTV', 'DeviceProtection', 'PaperlessBilling', 'OnlineBackup', 'StreamingMovies', 'MultipleLines', 'PhoneService', 'gender', 'PaymentMethod', 'Contract', 'TechSupport', 'OnlineSecurity']\n"
     ]
    }
   ],
   "source": [
    "numCols = X_train.select_dtypes(\"number\").columns\n",
    "catCols = X_train.select_dtypes(\"object\").columns\n",
    "numCols= list(set(numCols))\n",
    "catCols= list(set(catCols))\n",
    "print (numCols,catCols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Create a dict for categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: None,\n",
       " 2: None,\n",
       " 3: None,\n",
       " 5: None,\n",
       " 6: None,\n",
       " 7: None,\n",
       " 8: None,\n",
       " 9: None,\n",
       " 10: None,\n",
       " 11: None,\n",
       " 12: None,\n",
       " 13: None,\n",
       " 14: None,\n",
       " 15: None,\n",
       " 16: None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "categories_per_feature = {}\n",
    "for i in range (len(final_set.columns)):\n",
    "    if final_set.columns[i] in catCols:\n",
    "        categories_per_feature[i] = None\n",
    "categories_per_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cd = TabularDrift(X_train.values, p_val=.05, categories_per_feature=categories_per_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'alibi_detect.cd.tabular.TabularDrift'>: it's not found as alibi_detect.cd.tabular.TabularDrift",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b4ed3c567096>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model1.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mis_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m             \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0mNumpyPickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/pickle.py\u001b[0m in \u001b[0;36mdump\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSTOP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_framing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;31m# Save the reduce() output and finally memoize the object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_reduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_reduce\u001b[0;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[1;32m    683\u001b[0m                     \"args[0] from __newobj__ args has the wrong class\")\n\u001b[1;32m    684\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m             \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNEWOBJ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/pickle.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;31m# class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_global\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/pickle.py\u001b[0m in \u001b[0;36msave_global\u001b[0;34m(self, obj, name)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mobj2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             raise PicklingError(\n\u001b[0m\u001b[1;32m   1069\u001b[0m                 \u001b[0;34m\"Can't pickle %r: it's not found as %s.%s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                 (obj, module_name, name)) from None\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'alibi_detect.cd.tabular.TabularDrift'>: it's not found as alibi_detect.cd.tabular.TabularDrift"
     ]
    }
   ],
   "source": [
    "\n",
    "joblib.dump(cd, 'model1.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_detector(cd, 'CustomerChurnDriftPredictor')\n",
    "# cd1 = load_detector('CustomerChurnDriftPredictor')\n",
    "latest_run_id = mlflow.search_runs().sort_values('start_time').run_id.values[-1]\n",
    "with mlflow.start_run(run_id=latest_run_id):\n",
    "  mlflow.log_artifacts('model', 'model/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "`python_model` must be a subclass of `PythonModel`. Instead, found an object of type: <class 'alibi_detect.cd.tabular.TabularDrift'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-3a0bdb13c693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTabularDrift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategories_per_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategories_per_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         mlflow.pyfunc.add_to_model(cd, cd.predict, data=categories_per_feature, code=None, env=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mpython_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mrecord_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/mlflow/pyfunc/__init__.py\u001b[0m in \u001b[0;36mlog_model\u001b[0;34m(artifact_path, loader_module, data_path, code_path, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements)\u001b[0m\n\u001b[1;32m   1200\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mextra_pip_requirements\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0mextra_pip_requirements\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m     \"\"\"\n\u001b[0;32m-> 1202\u001b[0;31m     return Model.log(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m         \u001b[0mflavor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/mlflow/models/model.py\u001b[0m in \u001b[0;36mlog\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0mrun_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_or_start_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mmlflow_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0martifact_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mflavor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlflow_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmlflow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfluent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martifact_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/mlflow/pyfunc/__init__.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(path, loader_module, data_path, code_path, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m         )\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msecond_argument_set_specified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m         return mlflow.pyfunc.model._save_model_with_class_artifacts_params(\n\u001b[0m\u001b[1;32m   1090\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0mpython_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpython_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/mlflow/pyfunc/model.py\u001b[0m in \u001b[0;36m_save_model_with_class_artifacts_params\u001b[0;34m(path, python_model, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0mcustom_model_config_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCONFIG_KEY_PYTHON_MODEL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaved_python_model_subpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         raise MlflowException(\n\u001b[0m\u001b[1;32m    166\u001b[0m             message=(\n\u001b[1;32m    167\u001b[0m                 \u001b[0;34m\"`python_model` must be a subclass of `PythonModel`. Instead, found an\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMlflowException\u001b[0m: `python_model` must be a subclass of `PythonModel`. Instead, found an object of type: <class 'alibi_detect.cd.tabular.TabularDrift'>"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(tags= {\n",
    "        \"mlflow.source.git.commit\" : get_git_revision_hash() ,\n",
    "        \"mlflow.user\": get_git_user(),\n",
    "        \"mlflow.source.git.repoURL\": get_git_remote(),\n",
    "        \"git_remote\": get_git_remote(),\n",
    "        \"mlflow.source.git.branch\": get_git_branch(),\n",
    "        \"mlflow.docker.image.name\": os.getenv(\"JUPYTER_IMAGE\", \"LOCAL\"),\n",
    "        \"mlflow.source.type\": \"NOTEBOOK\",\n",
    "#         \"mlflow.source.name\": ipynbname.name()\n",
    "    }) as run:\n",
    "        cd = TabularDrift(X_train.values, p_val=.05, categories_per_feature=categories_per_feature)\n",
    "#         mlflow.pyfunc.add_to_model(cd, cd.predict, data=categories_per_feature, code=None, env=None)\n",
    "        mlflow.pyfunc.log_model('/tmp',  python_model=cd)\n",
    "\n",
    "        record_details(mlflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "params, metrics, tags, artifacts = fetch_logged_data(run.info.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active run_id: b02181f779544bdea30caa714aaaf7a4\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.start_run()\n",
    "run = mlflow.active_run()\n",
    "print(\"Active run_id: {}\".format(run.info.run_id))\n",
    "mlflow.log_param(\"my\", \"param\")\n",
    "mlflow.log_metric(\"score\", 100)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.log_param(\"my\", \"param\")\n",
    "    mlflow.log_metric(\"score\", 100)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with mlflow.start_run() as run:\n",
    "    cd = TabularDrift(X_train.values, p_val=.05, categories_per_feature=categories_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_for_check = X_test.copy()\n",
    "list_dist = []\n",
    "list_dist_d= []\n",
    "list_dist_nd= []\n",
    "\n",
    "list_drift = []\n",
    "list_drift_index = []\n",
    "idx =0\n",
    "cc = 0\n",
    "for index, row in data_for_check.iterrows():\n",
    "    cd_preds = cd.predict(data_for_check.iloc[idx].values.reshape(1,data_for_check.shape[1]))\n",
    "    if cd_preds['data']['is_drift']==1:\n",
    "        list_drift_index.append(idx)\n",
    "        list_dist_d.append(np.min(cd_preds['data']['p_val']))\n",
    "\n",
    "    else:\n",
    "        list_dist_nd.append(np.min(cd_preds['data']['p_val']))\n",
    "\n",
    "    list_drift.append(cd_preds['data']['is_drift'])\n",
    "    list_dist.append(np.mean(cd_preds['data']['p_val']))\n",
    "    idx +=1\n",
    "len (list_drift_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
      "  elif pd.api.types.is_categorical(cols):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines_1</th>\n",
       "      <th>MultipleLines_2</th>\n",
       "      <th>MultipleLines_3</th>\n",
       "      <th>InternetService_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Contract_1</th>\n",
       "      <th>Contract_2</th>\n",
       "      <th>Contract_3</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod_1</th>\n",
       "      <th>PaymentMethod_2</th>\n",
       "      <th>PaymentMethod_3</th>\n",
       "      <th>PaymentMethod_4</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.65</td>\n",
       "      <td>45.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.15</td>\n",
       "      <td>385.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.65</td>\n",
       "      <td>330.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43.75</td>\n",
       "      <td>903.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74.10</td>\n",
       "      <td>5222.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  SeniorCitizen  Partner  Dependents  tenure  PhoneService  \\\n",
       "0       1              0        1           1       1             1   \n",
       "1       1              0        2           2       4             1   \n",
       "2       2              1        1           1      17             1   \n",
       "3       1              0        1           1      22             2   \n",
       "4       2              0        2           2      70             1   \n",
       "\n",
       "   MultipleLines_1  MultipleLines_2  MultipleLines_3  InternetService_1  ...  \\\n",
       "0                1                0                0                  1  ...   \n",
       "1                0                1                0                  0  ...   \n",
       "2                1                0                0                  0  ...   \n",
       "3                0                0                1                  1  ...   \n",
       "4                1                0                0                  1  ...   \n",
       "\n",
       "   Contract_1  Contract_2  Contract_3  PaperlessBilling  PaymentMethod_1  \\\n",
       "0           1           0           0                 1                1   \n",
       "1           1           0           0                 2                1   \n",
       "2           0           1           0                 2                0   \n",
       "3           0           1           0                 1                0   \n",
       "4           0           1           0                 2                0   \n",
       "\n",
       "   PaymentMethod_2  PaymentMethod_3  PaymentMethod_4  MonthlyCharges  \\\n",
       "0                0                0                0           45.65   \n",
       "1                0                0                0          101.15   \n",
       "2                1                0                0           20.65   \n",
       "3                0                1                0           43.75   \n",
       "4                0                0                1           74.10   \n",
       "\n",
       "   TotalCharges  \n",
       "0         45.65  \n",
       "1        385.90  \n",
       "2        330.60  \n",
       "3        903.60  \n",
       "4       5222.30  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Churn'] = data['Churn'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "data.replace(\" \", np.nan, inplace=True)\n",
    "\n",
    "data['TotalCharges'] = pd.to_numeric(data['TotalCharges'])\n",
    "\n",
    "mean = data['TotalCharges'].mean()\n",
    "data.fillna(mean, inplace=True)\n",
    "\n",
    "\n",
    "names = ['gender', 'Partner', 'Dependents', 'PhoneService', 'StreamingTV', 'StreamingMovies', 'PaperlessBilling']\n",
    "# for column in names:\n",
    "#     labelencoder(column)\n",
    "data_enc = data\n",
    "data_enc = data_enc.drop(['Churn', 'customerID'], axis=1)\n",
    "enc = ce.ordinal.OrdinalEncoder(cols=names)\n",
    "enc.fit(data_enc)\n",
    "# ###\n",
    "# filename_oe = 'OrdinalEncoder_drift.sav'\n",
    "# pickle.dump(enc, open(filename_oe, 'wb'))\n",
    "\n",
    "# # some time later...\n",
    "\n",
    "# # load the model from disk\n",
    "# enc = pickle.load(open(filename_oe, 'rb'))\n",
    "# ###\n",
    "labelled_set = enc.transform(data_enc)\n",
    "\n",
    "names = ['MultipleLines', 'InternetService', 'Contract', 'PaymentMethod', 'OnlineSecurity', 'OnlineBackup',\n",
    "         'DeviceProtection', 'TechSupport']\n",
    "\n",
    "ohe = ce.OneHotEncoder(cols=names)\n",
    "data_ohe = data\n",
    "data_ohe = data_ohe.drop(['Churn', 'customerID'], axis=1)\n",
    "ohe.fit(data_ohe)\n",
    "# ###\n",
    "# filename_ohe = 'OneHotEncoder_drift.sav'\n",
    "# pickle.dump(ohe, open(filename_ohe, 'wb'))\n",
    "\n",
    "# # some time later...\n",
    "\n",
    "# # load the model from disk\n",
    "# ohe = pickle.load(open(filename_ohe, 'rb'))\n",
    "###\n",
    "final_set = ohe.transform(labelled_set)\n",
    "columns_name =final_set.columns\n",
    "final_set.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "labels = data['Churn']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(final_set, labels, test_size=0.3)\n",
    "\n",
    "Y = data['Churn']\n",
    "X = final_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 36, 32)            160       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 36, 64)            8256      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 36, 4)             1028      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 144)               0         \n",
      "=================================================================\n",
      "Total params: 9,444\n",
      "Trainable params: 9,444\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, InputLayer, Input,Conv1D,Flatten,Embedding\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "\n",
    "proj = tf.keras.Sequential(\n",
    "  [\n",
    "      InputLayer(input_shape=( n_features,1), name=\"encode1\"),\n",
    "\n",
    "      Conv1D(32, 4, strides=1, padding='same', activation=tf.nn.relu),\n",
    "      Conv1D(64, 4, strides=1, padding='same', activation=tf.nn.relu),\n",
    "      Conv1D(4, 4, strides=1, padding='same', activation=tf.nn.relu),\n",
    "      Flatten(),\n",
    "  ]\n",
    ")\n",
    "\n",
    "proj.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alibi_detect.utils.tensorflow.kernels import DeepKernel\n",
    "kernel = DeepKernel(proj, eps=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2113, 36, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = X_train.values.reshape(X_train.values.shape[0], X_train.values.shape[1], 1)\n",
    "# x_t = X_test.values.reshape(X_test.values.shape[0], X_test.values.shape[1], 1).astype('float32')\n",
    "x = X_train.values.reshape(X_train.values.shape[0],n_features,1).astype('float32')\n",
    "x_t = X_test.values.reshape(X_test.values.shape[0],n_features,1).astype('float32')\n",
    "x_t.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from alibi_detect.cd import LearnedKernelDrift\n",
    "cd = LearnedKernelDrift(x, kernel, backend='tensorflow', p_val=.05, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 36, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_t0 = x_t[0].reshape(1,n_features,1).astype('float32')\n",
    "\n",
    "x_t0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ab99e0a7b1fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata_for_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcd_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/cd/learned_kernel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, return_p_val, return_distance, return_kernel)\u001b[0m\n\u001b[1;32m    158\u001b[0m             \u001b[0mtrained\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \"\"\"\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_detector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_p_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/cd/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, return_p_val, return_distance, return_kernel)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \"\"\"\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# compute drift scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_permutations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mdrift_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_val\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/cd/tensorflow/learned_kernel.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mkernel_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_mat_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mkernel_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_mat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag_part\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# zero diagonal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mmmd2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmmd2_from_kernel_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cur_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_diag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         mmd2_permuted = np.array(\n\u001b[1;32m    176\u001b[0m             [mmd2_from_kernel_matrix(kernel_mat, len(x_cur_te), permute=True, zero_diag=False).numpy()\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/alibi_detect/utils/tensorflow/distance.py\u001b[0m in \u001b[0;36mmmd2_from_kernel_matrix\u001b[0;34m(kernel_mat, m, permute, zero_diag)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mkernel_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mk_xx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_yy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m     \u001b[0mc_xx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m     \u001b[0mmmd2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_xx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_xx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc_yy\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_yy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_xy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmmd2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "data_for_check = X_test.copy()\n",
    "\n",
    "cd_preds = cd.predict(x_t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_check = X_test.copy()\n",
    "list_dist = []\n",
    "list_dist_d= []\n",
    "list_dist_nd= []\n",
    "\n",
    "list_drift = []\n",
    "list_drift_index = []\n",
    "idx =0\n",
    "cc = 0\n",
    "for index, row in data_for_check.iterrows(): \n",
    "    x_t0 = x_t[idx].reshape(1,n_features,1).astype('float32')\n",
    "    cd_preds = cd.predict(x_t0)\n",
    "    # cd_preds = cd.predict(data_for_check.iloc[idx].values.reshape(1,data_for_check.shape[1]))\n",
    "    if cd_preds['data']['is_drift']==1:\n",
    "        list_drift_index.append(idx)\n",
    "        list_dist_d.append(np.min(cd_preds['data']['p_val']))\n",
    "        \n",
    "    else:\n",
    "        list_dist_nd.append(np.min(cd_preds['data']['p_val']))\n",
    "\n",
    "    list_drift.append(cd_preds['data']['is_drift'])\n",
    "    list_dist.append(np.mean(cd_preds['data']['p_val']))\n",
    "    idx +=1\n",
    "len (list_drift_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ce4b14861374cad230d871e5c41f613d2db9594bea8f9eafa29f3d4d2b36a9d4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
